{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tvAKGat01Sd"
      },
      "source": [
        "# **Penting**\n",
        "- Jangan mengubah atau menambahkan cell text yang sudah disediakan, Anda hanya perlu mengerjakan cell code yang sudah disediakan.\n",
        "- Pastikan seluruh kriteria memiliki output yang sesuai, karena jika tidak ada output dianggap tidak selesai.\n",
        "- Misal, Anda menggunakan df = df.dropna() silakan gunakan df.isnull().sum() sebagai tanda sudah berhasil. Silakan sesuaikan seluruh output dengan perintah yang sudah disediakan.\n",
        "- Pastikan Anda melakukan Run All sebelum mengirimkan submission untuk memastikan seluruh cell berjalan dengan baik.\n",
        "- Pastikan Anda menggunakan variabel df dari awal sampai akhir dan tidak diperbolehkan mengganti nama variabel tersebut.\n",
        "- Hapus simbol pagar (#) pada kode yang bertipe komentar jika Anda menerapkan kriteria tambahan\n",
        "- Biarkan simbol pagar (#) jika Anda tidak menerapkan kriteria tambahan\n",
        "- Pastikan Anda mengerjakan sesuai section yang sudah diberikan tanpa mengubah judul atau header yang disediakan."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKADPWcFKlj3"
      },
      "source": [
        "# **1. Import Library**\n",
        "Pada tahap ini, Anda perlu mengimpor beberapa pustaka (library) Python yang dibutuhkan untuk analisis data dan pembangunan model machine learning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "BlmvjLY9M4Yj"
      },
      "outputs": [],
      "source": [
        "#Type your code here\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, ConfusionMatrixDisplay"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3YIEnAFKrKL"
      },
      "source": [
        "# **2. Memuat Dataset dari Hasil Clustering**\n",
        "Memuat dataset hasil clustering dari file CSV ke dalam variabel DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "GHCGNTyrM5fS"
      },
      "outputs": [],
      "source": [
        "# Gunakan dataset hasil clustering yang memiliki fitur Target\n",
        "# Silakan gunakan dataset data_clustering jika tidak menerapkan Interpretasi Hasil Clustering [Advanced]\n",
        "# Silakan gunakan dataset data_clustering_inverse jika menerapkan Interpretasi Hasil Clustering [Advanced]\n",
        "# Lengkapi kode berikut\n",
        "df = pd.read_csv(\"data_clustering_inverse.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "bCsep0NZ0LUf"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TransactionAmount</th>\n",
              "      <th>TransactionDate</th>\n",
              "      <th>TransactionType</th>\n",
              "      <th>Location</th>\n",
              "      <th>Channel</th>\n",
              "      <th>CustomerAge</th>\n",
              "      <th>CustomerOccupation</th>\n",
              "      <th>TransactionDuration</th>\n",
              "      <th>LoginAttempts</th>\n",
              "      <th>AccountBalance</th>\n",
              "      <th>PreviousTransactionDate</th>\n",
              "      <th>AgeGroupOrdinal</th>\n",
              "      <th>AgeGroup</th>\n",
              "      <th>Target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14.09</td>\n",
              "      <td>2023-04-11 16:29:14</td>\n",
              "      <td>Debit</td>\n",
              "      <td>San Diego</td>\n",
              "      <td>ATM</td>\n",
              "      <td>70.0</td>\n",
              "      <td>Doctor</td>\n",
              "      <td>81.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5112.21</td>\n",
              "      <td>2024-11-04 08:08:08</td>\n",
              "      <td>2</td>\n",
              "      <td>Older Adult</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>376.24</td>\n",
              "      <td>2023-06-27 16:44:19</td>\n",
              "      <td>Debit</td>\n",
              "      <td>Houston</td>\n",
              "      <td>ATM</td>\n",
              "      <td>68.0</td>\n",
              "      <td>Doctor</td>\n",
              "      <td>141.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>13758.91</td>\n",
              "      <td>2024-11-04 08:09:35</td>\n",
              "      <td>2</td>\n",
              "      <td>Older Adult</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>126.29</td>\n",
              "      <td>2023-07-10 18:16:08</td>\n",
              "      <td>Debit</td>\n",
              "      <td>Mesa</td>\n",
              "      <td>Online</td>\n",
              "      <td>19.0</td>\n",
              "      <td>Student</td>\n",
              "      <td>56.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1122.35</td>\n",
              "      <td>2024-11-04 08:07:04</td>\n",
              "      <td>3</td>\n",
              "      <td>Teen</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>184.50</td>\n",
              "      <td>2023-05-05 16:32:11</td>\n",
              "      <td>Debit</td>\n",
              "      <td>Raleigh</td>\n",
              "      <td>Online</td>\n",
              "      <td>26.0</td>\n",
              "      <td>Student</td>\n",
              "      <td>25.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>8569.06</td>\n",
              "      <td>2024-11-04 08:09:06</td>\n",
              "      <td>4</td>\n",
              "      <td>Young Adult</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13.45</td>\n",
              "      <td>2023-10-16 17:51:24</td>\n",
              "      <td>Credit</td>\n",
              "      <td>Atlanta</td>\n",
              "      <td>Online</td>\n",
              "      <td>45.0</td>\n",
              "      <td>Student</td>\n",
              "      <td>198.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>7429.40</td>\n",
              "      <td>2024-11-04 08:06:39</td>\n",
              "      <td>0</td>\n",
              "      <td>Adult</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   TransactionAmount      TransactionDate  ...     AgeGroup Target\n",
              "0              14.09  2023-04-11 16:29:14  ...  Older Adult      0\n",
              "1             376.24  2023-06-27 16:44:19  ...  Older Adult      0\n",
              "2             126.29  2023-07-10 18:16:08  ...         Teen      1\n",
              "3             184.50  2023-05-05 16:32:11  ...  Young Adult      1\n",
              "4              13.45  2023-10-16 17:51:24  ...        Adult      0\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Tampilkan 5 baris pertama dengan function head.\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkPem5eWL2UP"
      },
      "source": [
        "# **3. Data Splitting**\n",
        "Tahap Data Splitting bertujuan untuk memisahkan dataset menjadi dua bagian: data latih (training set) dan data uji (test set)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "OubAW-7ONKVj"
      },
      "outputs": [],
      "source": [
        "# Menggunakan train_test_split() untuk melakukan pembagian dataset.\n",
        "label_encoder = LabelEncoder()\n",
        "scaler = MinMaxScaler()\n",
        "df_encoded = df.copy()\n",
        "\n",
        "df_encoded = df_encoded.drop(columns=['TransactionDate','TransactionType','Location','PreviousTransactionDate', 'AgeGroup','AgeGroupOrdinal'])\n",
        "\n",
        "cat_columns = df_encoded.select_dtypes(exclude=['number']).columns\n",
        "num_columns = [col for col in df_encoded.select_dtypes(include=['float64', 'int64']).columns \n",
        "               if col != 'Target']\n",
        "\n",
        "for col in cat_columns:\n",
        "    df_encoded[col] = label_encoder.fit_transform(df_encoded[col])\n",
        "\n",
        "df_encoded[num_columns] = scaler.fit_transform(df_encoded[num_columns])\n",
        "\n",
        "X = df_encoded.drop(columns=['Target'])\n",
        "y = df_encoded['Target']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# print(f\"Training set shape: X_train={X_train.shape}, y_train={y_train.shape}\")\n",
        "# print(f\"Test set shape: X_test={X_test.shape}, y_test={y_test.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVPbB03CMhTT"
      },
      "source": [
        "# **4. Membangun Model Klasifikasi**\n",
        "Setelah memilih algoritma klasifikasi yang sesuai, langkah selanjutnya adalah melatih model menggunakan data latih.\n",
        "\n",
        "Berikut adalah rekomendasi tahapannya.\n",
        "1. Menggunakan algoritma klasifikasi yaitu Decision Tree.\n",
        "2. Latih model menggunakan data yang sudah dipisah."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "4JYxBe87NLDk"
      },
      "outputs": [],
      "source": [
        "# Buatlah model klasifikasi menggunakan Decision Tree\n",
        "dt = DecisionTreeClassifier().fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "P_AakAxghYv-"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['decision_tree_model.h5']"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Menyimpan Model\n",
        "import joblib\n",
        "joblib.dump(dt, 'decision_tree_model.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epO4HhrzBXMg"
      },
      "source": [
        "# **5. Memenuhi Kriteria Skilled dan Advanced dalam Membangun Model Klasifikasi**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNOEZk24uiXu"
      },
      "source": [
        "**Biarkan kosong jika tidak menerapkan kriteria skilled atau advanced**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "kB_8LIWMATl6"
      },
      "outputs": [],
      "source": [
        "# Melatih model menggunakan algoritma klasifikasi scikit-learn selain Decision Tree.\n",
        "rf = RandomForestClassifier().fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "bRlKm5BVAT91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                Model  Accuracy  Precision    Recall  F1-Score\n",
            "0  Decision Tree (DT)  0.994036   0.990658  0.992529  0.991580\n",
            "1  Random Forest (RF)  0.982107   0.978926  0.972165  0.975437\n"
          ]
        }
      ],
      "source": [
        "# Menampilkan hasil evaluasi akurasi, presisi, recall, dan F1-Score pada seluruh algoritma yang sudah dibuat.\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    y_pred = model.predict(X_test)\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    results = {\n",
        "        'Confusion Matrix': cm,\n",
        "        'Accuracy': accuracy_score(y_test, y_pred),\n",
        "        'Precision': precision_score(y_test, y_pred, average='macro'),\n",
        "        'Recall': recall_score(y_test, y_pred, average='macro'),\n",
        "        'F1-Score': f1_score(y_test, y_pred, average='macro')\n",
        "    }\n",
        "    return results\n",
        "\n",
        "# Evaluate each model and collect results\n",
        "results = {\n",
        "    'Decision Tree (DT)': evaluate_model(dt, X_test, y_test),\n",
        "    'Random Forest (RF)': evaluate_model(rf, X_test, y_test),\n",
        "}\n",
        "\n",
        "# Create a DataFrame to summarize results\n",
        "summary_df = pd.DataFrame(columns=['Model', 'Accuracy', 'Precision', 'Recall', 'F1-Score'])\n",
        "\n",
        "# Populate the DataFrame with results\n",
        "rows = []\n",
        "for model_name, metrics in results.items():\n",
        "    rows.append({\n",
        "        'Model': model_name,\n",
        "        'Accuracy': metrics['Accuracy'],\n",
        "        'Precision': metrics['Precision'],\n",
        "        'Recall': metrics['Recall'],\n",
        "        'F1-Score': metrics['F1-Score']\n",
        "    })\n",
        "\n",
        "# Convert list of dictionaries to DataFrame\n",
        "summary_df = pd.DataFrame(rows)\n",
        "\n",
        "# Display the summary DataFrame\n",
        "print(summary_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "dUPItkbXBNkO"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['explore_random-forest_classification.h5']"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Menyimpan Model Selain Decision Tree\n",
        "# Model ini bisa lebih dari satu\n",
        "import joblib\n",
        "joblib.dump(dt, 'explore_desion-tree_classification.h5')\n",
        "joblib.dump(rf, 'explore_random-forest_classification.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u23H2guj-h9h"
      },
      "source": [
        "Hyperparameter Tuning Model\n",
        "\n",
        "Pilih salah satu algoritma yang ingin Anda tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "dFCTxJJq-m-l"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV] END criterion=gini, max_depth=39, min_samples_split=9, n_estimators=226; total time=   0.2s\n",
            "[CV] END criterion=gini, max_depth=39, min_samples_split=9, n_estimators=226; total time=   0.2s\n",
            "[CV] END criterion=gini, max_depth=39, min_samples_split=9, n_estimators=226; total time=   0.2s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV] END criterion=entropy, max_depth=45, min_samples_split=4, n_estimators=480; total time=   0.5s\n",
            "[CV] END criterion=entropy, max_depth=45, min_samples_split=4, n_estimators=480; total time=   0.6s\n",
            "[CV] END criterion=entropy, max_depth=45, min_samples_split=4, n_estimators=480; total time=   0.5s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV] END criterion=gini, max_depth=47, min_samples_split=3, n_estimators=273; total time=   0.3s\n",
            "[CV] END criterion=gini, max_depth=47, min_samples_split=3, n_estimators=273; total time=   0.3s\n",
            "[CV] END criterion=gini, max_depth=47, min_samples_split=3, n_estimators=273; total time=   0.3s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV] END criterion=entropy, max_depth=17, min_samples_split=7, n_estimators=421; total time=   0.5s\n",
            "[CV] END criterion=entropy, max_depth=17, min_samples_split=7, n_estimators=421; total time=   0.5s\n",
            "[CV] END criterion=entropy, max_depth=17, min_samples_split=7, n_estimators=421; total time=   0.4s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV] END criterion=entropy, max_depth=28, min_samples_split=6, n_estimators=386; total time=   0.4s\n",
            "[CV] END criterion=entropy, max_depth=28, min_samples_split=6, n_estimators=386; total time=   0.4s\n",
            "[CV] END criterion=entropy, max_depth=28, min_samples_split=6, n_estimators=386; total time=   0.4s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV] END criterion=entropy, max_depth=48, min_samples_split=3, n_estimators=175; total time=   0.2s\n",
            "[CV] END criterion=entropy, max_depth=48, min_samples_split=3, n_estimators=175; total time=   0.2s\n",
            "[CV] END criterion=entropy, max_depth=48, min_samples_split=3, n_estimators=175; total time=   0.2s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV] END criterion=entropy, max_depth=41, min_samples_split=5, n_estimators=450; total time=   0.5s\n",
            "[CV] END criterion=entropy, max_depth=41, min_samples_split=5, n_estimators=450; total time=   0.5s\n",
            "[CV] END criterion=entropy, max_depth=41, min_samples_split=5, n_estimators=450; total time=   0.5s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV] END criterion=entropy, max_depth=47, min_samples_split=6, n_estimators=435; total time=   0.5s\n",
            "[CV] END criterion=entropy, max_depth=47, min_samples_split=6, n_estimators=435; total time=   0.5s\n",
            "[CV] END criterion=entropy, max_depth=47, min_samples_split=6, n_estimators=435; total time=   0.4s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV] END criterion=entropy, max_depth=38, min_samples_split=9, n_estimators=266; total time=   0.3s\n",
            "[CV] END criterion=entropy, max_depth=38, min_samples_split=9, n_estimators=266; total time=   0.3s\n",
            "[CV] END criterion=entropy, max_depth=38, min_samples_split=9, n_estimators=266; total time=   0.3s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV] END criterion=gini, max_depth=43, min_samples_split=8, n_estimators=202; total time=   0.2s\n",
            "[CV] END criterion=gini, max_depth=43, min_samples_split=8, n_estimators=202; total time=   0.2s\n",
            "[CV] END criterion=gini, max_depth=43, min_samples_split=8, n_estimators=202; total time=   0.2s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV] END criterion=gini, max_depth=46, min_samples_split=2, n_estimators=113; total time=   0.1s\n",
            "[CV] END criterion=gini, max_depth=46, min_samples_split=2, n_estimators=113; total time=   0.1s\n",
            "[CV] END criterion=gini, max_depth=46, min_samples_split=2, n_estimators=113; total time=   0.1s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV] END criterion=gini, max_depth=10, min_samples_split=2, n_estimators=127; total time=   0.1s\n",
            "[CV] END criterion=gini, max_depth=10, min_samples_split=2, n_estimators=127; total time=   0.1s\n",
            "[CV] END criterion=gini, max_depth=10, min_samples_split=2, n_estimators=127; total time=   0.1s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV] END criterion=gini, max_depth=23, min_samples_split=3, n_estimators=109; total time=   0.1s\n",
            "[CV] END criterion=gini, max_depth=23, min_samples_split=3, n_estimators=109; total time=   0.1s\n",
            "[CV] END criterion=gini, max_depth=23, min_samples_split=3, n_estimators=109; total time=   0.1s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV] END criterion=entropy, max_depth=21, min_samples_split=10, n_estimators=482; total time=   0.5s\n",
            "[CV] END criterion=entropy, max_depth=21, min_samples_split=10, n_estimators=482; total time=   0.5s\n",
            "[CV] END criterion=entropy, max_depth=21, min_samples_split=10, n_estimators=482; total time=   0.5s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV] END criterion=gini, max_depth=25, min_samples_split=2, n_estimators=109; total time=   0.1s\n",
            "[CV] END criterion=gini, max_depth=25, min_samples_split=2, n_estimators=109; total time=   0.1s\n",
            "[CV] END criterion=gini, max_depth=25, min_samples_split=2, n_estimators=109; total time=   0.1s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV] END criterion=gini, max_depth=33, min_samples_split=2, n_estimators=466; total time=   0.5s\n",
            "[CV] END criterion=gini, max_depth=33, min_samples_split=2, n_estimators=466; total time=   0.5s\n",
            "[CV] END criterion=gini, max_depth=33, min_samples_split=2, n_estimators=466; total time=   0.5s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV] END criterion=gini, max_depth=24, min_samples_split=2, n_estimators=136; total time=   0.2s\n",
            "[CV] END criterion=gini, max_depth=24, min_samples_split=2, n_estimators=136; total time=   0.2s\n",
            "[CV] END criterion=gini, max_depth=24, min_samples_split=2, n_estimators=136; total time=   0.2s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV] END criterion=gini, max_depth=14, min_samples_split=2, n_estimators=156; total time=   0.2s\n",
            "[CV] END criterion=gini, max_depth=14, min_samples_split=2, n_estimators=156; total time=   0.2s\n",
            "[CV] END criterion=gini, max_depth=14, min_samples_split=2, n_estimators=156; total time=   0.2s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV] END criterion=entropy, max_depth=31, min_samples_split=9, n_estimators=100; total time=   0.2s\n",
            "[CV] END criterion=entropy, max_depth=31, min_samples_split=9, n_estimators=100; total time=   0.2s\n",
            "[CV] END criterion=entropy, max_depth=31, min_samples_split=9, n_estimators=100; total time=   0.1s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV] END criterion=gini, max_depth=26, min_samples_split=3, n_estimators=143; total time=   0.2s\n",
            "[CV] END criterion=gini, max_depth=26, min_samples_split=3, n_estimators=143; total time=   0.2s\n",
            "[CV] END criterion=gini, max_depth=26, min_samples_split=3, n_estimators=143; total time=   0.2s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV] END criterion=entropy, max_depth=35, min_samples_split=9, n_estimators=101; total time=   0.1s\n",
            "[CV] END criterion=entropy, max_depth=35, min_samples_split=9, n_estimators=101; total time=   0.1s\n",
            "[CV] END criterion=entropy, max_depth=35, min_samples_split=9, n_estimators=101; total time=   0.1s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV] END criterion=gini, max_depth=50, min_samples_split=9, n_estimators=445; total time=   0.5s\n",
            "[CV] END criterion=gini, max_depth=50, min_samples_split=9, n_estimators=445; total time=   0.5s\n",
            "[CV] END criterion=gini, max_depth=50, min_samples_split=9, n_estimators=445; total time=   0.5s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV] END criterion=gini, max_depth=19, min_samples_split=2, n_estimators=152; total time=   0.2s\n",
            "[CV] END criterion=gini, max_depth=19, min_samples_split=2, n_estimators=152; total time=   0.2s\n",
            "[CV] END criterion=gini, max_depth=19, min_samples_split=2, n_estimators=152; total time=   0.2s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV] END criterion=gini, max_depth=19, min_samples_split=2, n_estimators=142; total time=   0.2s\n",
            "[CV] END criterion=gini, max_depth=19, min_samples_split=2, n_estimators=142; total time=   0.1s\n",
            "[CV] END criterion=gini, max_depth=19, min_samples_split=2, n_estimators=142; total time=   0.2s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV] END criterion=entropy, max_depth=12, min_samples_split=10, n_estimators=443; total time=   0.5s\n",
            "[CV] END criterion=entropy, max_depth=12, min_samples_split=10, n_estimators=443; total time=   0.5s\n",
            "[CV] END criterion=entropy, max_depth=12, min_samples_split=10, n_estimators=443; total time=   0.5s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV] END criterion=gini, max_depth=30, min_samples_split=2, n_estimators=469; total time=   0.5s\n",
            "[CV] END criterion=gini, max_depth=30, min_samples_split=2, n_estimators=469; total time=   0.5s\n",
            "[CV] END criterion=gini, max_depth=30, min_samples_split=2, n_estimators=469; total time=   0.5s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV] END criterion=gini, max_depth=36, min_samples_split=2, n_estimators=418; total time=   0.4s\n",
            "[CV] END criterion=gini, max_depth=36, min_samples_split=2, n_estimators=418; total time=   0.4s\n",
            "[CV] END criterion=gini, max_depth=36, min_samples_split=2, n_estimators=418; total time=   0.4s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV] END criterion=gini, max_depth=18, min_samples_split=2, n_estimators=140; total time=   0.1s\n",
            "[CV] END criterion=gini, max_depth=18, min_samples_split=2, n_estimators=140; total time=   0.2s\n",
            "[CV] END criterion=gini, max_depth=18, min_samples_split=2, n_estimators=140; total time=   0.2s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV] END criterion=gini, max_depth=16, min_samples_split=2, n_estimators=102; total time=   0.1s\n",
            "[CV] END criterion=gini, max_depth=16, min_samples_split=2, n_estimators=102; total time=   0.1s\n",
            "[CV] END criterion=gini, max_depth=16, min_samples_split=2, n_estimators=102; total time=   0.1s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV] END criterion=gini, max_depth=20, min_samples_split=2, n_estimators=133; total time=   0.2s\n",
            "[CV] END criterion=gini, max_depth=20, min_samples_split=2, n_estimators=133; total time=   0.1s\n",
            "[CV] END criterion=gini, max_depth=20, min_samples_split=2, n_estimators=133; total time=   0.1s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV] END criterion=entropy, max_depth=40, min_samples_split=2, n_estimators=169; total time=   0.2s\n",
            "[CV] END criterion=entropy, max_depth=40, min_samples_split=2, n_estimators=169; total time=   0.2s\n",
            "[CV] END criterion=entropy, max_depth=40, min_samples_split=2, n_estimators=169; total time=   0.2s\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV] END criterion=entropy, max_depth=19, min_samples_split=10, n_estimators=459; total time=   0.5s\n",
            "[CV] END criterion=entropy, max_depth=19, min_samples_split=10, n_estimators=459; total time=   0.5s\n",
            "[CV] END criterion=entropy, max_depth=19, min_samples_split=10, n_estimators=459; total time=   0.5s\n"
          ]
        }
      ],
      "source": [
        "# Lakukan Hyperparameter Tuning dan Latih ulang.\n",
        "# Lakukan dalam satu cell ini saja\n",
        "from skopt import BayesSearchCV\n",
        "\n",
        "# Definisikan ruang pencarian untuk Bayesian Optimization\n",
        "param_space = {\n",
        "    'n_estimators': (100, 500),\n",
        "    'max_depth': (10, 50),\n",
        "    'min_samples_split': (2, 10),\n",
        "    'criterion': ['gini', 'entropy']\n",
        "}\n",
        "\n",
        "# Inisialisasi BayesSearchCV\n",
        "bayes_search = BayesSearchCV(estimator=rf, search_spaces=param_space, n_iter=32, cv=3, n_jobs=-1, verbose=2, random_state=42)\n",
        "bayes_search.fit(X_train, y_train)\n",
        "\n",
        "# Output hasil terbaik\n",
        "# print(f\"Best parameters (Bayesian Optimization): {bayes_search.best_params_}\")\n",
        "best_rf_bayes = bayes_search.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "1g6EPSSWxjcQ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                       Model  Accuracy  Precision    Recall  F1-Score\n",
            "0  Random Forest (RF) before  0.982107   0.978926  0.972165  0.975437\n",
            "1   Random Forest (RF) after  0.980119   0.975163  0.970740  0.972904\n"
          ]
        }
      ],
      "source": [
        "# Menampilkan hasil evaluasi akurasi, presisi, recall, dan F1-Score pada algoritma yang sudah dituning.\n",
        "results = {\n",
        "    'Random Forest (RF) before': evaluate_model(rf, X_test, y_test),\n",
        "    'Random Forest (RF) after': evaluate_model(best_rf_bayes, X_test, y_test),\n",
        "}\n",
        "\n",
        "rows = []\n",
        "for model_name, metrics in results.items():\n",
        "    rows.append({\n",
        "        'Model': model_name,\n",
        "        'Accuracy': metrics['Accuracy'],\n",
        "        'Precision': metrics['Precision'],\n",
        "        'Recall': metrics['Recall'],\n",
        "        'F1-Score': metrics['F1-Score']\n",
        "    })\n",
        "\n",
        "summary_df = pd.DataFrame(data= rows,columns=['Model', 'Accuracy', 'Precision', 'Recall', 'F1-Score'])\n",
        "print(summary_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7UJNcVP--n7S"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['tuning_classification.h5']"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception ignored in: <function ResourceTracker.__del__ at 0x1037d5bc0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
            "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
            "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
            "ChildProcessError: [Errno 10] No child processes\n",
            "Exception ignored in: <function ResourceTracker.__del__ at 0x110869bc0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
            "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
            "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
            "ChildProcessError: [Errno 10] No child processes\n",
            "Exception ignored in: <function ResourceTracker.__del__ at 0x107289bc0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
            "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
            "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
            "ChildProcessError: [Errno 10] No child processes\n",
            "Exception ignored in: <function ResourceTracker.__del__ at 0x113601bc0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
            "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
            "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
            "ChildProcessError: [Errno 10] No child processes\n",
            "Exception ignored in: <function ResourceTracker.__del__ at 0x1055b9bc0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
            "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
            "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
            "ChildProcessError: [Errno 10] No child processes\n",
            "Exception ignored in: <function ResourceTracker.__del__ at 0x121169bc0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
            "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
            "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
            "ChildProcessError: [Errno 10] No child processes\n",
            "Exception ignored in: <function ResourceTracker.__del__ at 0x103971bc0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
            "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
            "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
            "ChildProcessError: [Errno 10] No child processes\n",
            "Exception ignored in: <function ResourceTracker.__del__ at 0x107969bc0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
            "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
            "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
            "ChildProcessError: [Errno 10] No child processes\n",
            "Exception ignored in: <function ResourceTracker.__del__ at 0x104ebdbc0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
            "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
            "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
            "ChildProcessError: [Errno 10] No child processes\n",
            "Exception ignored in: <function ResourceTracker.__del__ at 0x1112c9bc0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
            "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
            "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
            "ChildProcessError: [Errno 10] No child processes\n"
          ]
        }
      ],
      "source": [
        "# Menyimpan Model hasil tuning\n",
        "import joblib\n",
        "joblib.dump(best_rf_bayes, 'tuning_classification.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Hs4Xp4OiGEk"
      },
      "source": [
        "End of Code"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
